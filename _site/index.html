<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>aiaudit.org  </title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/aiaudit/assets/img/favicon.ico">
<link rel="stylesheet" href="/aiaudit/assets/css/main.css">

<link rel="canonical" href="/aiaudit/">

<!-- Theming-->




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center">
  <a href="mailto:%69%6E%66%6F@%61%69%61%75%64%69%74.%6F%72%67"><i class="fas fa-envelope"></i></a>
  
  
  
  
  <a href="https://github.com/aiaudit-org" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  
  
  
  
  
  
  
</span>

        </div>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/aiaudit/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/aiaudit/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/aiaudit/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/aiaudit/collaboration/">
                collaboration
                
              </a>
          </li>
          
          
          
          
          

          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">aiaudit.org</span>   
    </h1>
     <p class="desc">TODO</p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/aiaudit/assets/img/prof_pic.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p>Context and vision</p>

<p>Values, license</p>

<p>Short teaser text with the different areas of the menu being introduced (see miro)</p>


    </div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">BVM</abbr>
    
  

  
    <award class="badge">Oral</award>
  

  </div>

  <div id="MacBVM21" class="col-sm-8">
    
      <div class="title">Interval Neural Networks as Instability Detectors for Image Reconstructions</div>
      <div class="author">
        
          
          
          
            
              
                
                  Macdonald, Jan,
                
              
            
          
        
          
          
          
            
              
                
                  März, Maximilian,
                
              
            
          
        
          
          
          
            
              
                
                  Oala, Luis,
                
              
            
          
        
          
          
          
            
              
                
                  and Samek, Wojciech
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings Bildverarbeitung für die Medizin</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.bvm-workshop.org/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://arxiv.org/pdf/2003.13471.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This work investigates the detection of instabilities that may occur when utilizing deep learning models for image reconstruction tasks. Although neural networks often empirically outperform traditional reconstruction methods, their usage for sensitive medical applications remains controversial. Indeed, in a recent series of works, it has been demonstrated that deep learning approaches are susceptible to various types of instabilities, caused for instance by adversarial noise or out-of-distribution features. It is argued that this phenomenon can be observed regardless of the underlying architecture and that there is no easy remedy. Based on this insight, the present work demonstrates, how uncertainty quantification methods can be employed as instability detectors. In particular, it is shown that the recently proposed Interval Neural Networks are highly effective in revealing instabilities of reconstructions. Such an ability is crucial to ensure a safe use of deep learning-based methods for medical image reconstruction.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  

  
    <award class="badge">Spotlight<br>Top 10%</award>
  

  </div>

  <div id="pmlr-v136-oala20a" class="col-sm-8">
    
      <div class="title">ML4H Auditing: From Paper to Practice</div>
      <div class="author">
        
          
          
          
            
              
                
                  Oala, Luis,
                
              
            
          
        
          
          
          
            
              
                
                  Fehr, Jana,
                
              
            
          
        
          
          
          
            
              
                
                  Gilli, Luca,
                
              
            
          
        
          
          
          
            
              
                
                  Balachandran, Pradeep,
                
              
            
          
        
          
          
          
            
              
                
                  Leite, Alixandro Werneck,
                
              
            
          
        
          
          
          
            
              
                
                  Calderon-Ramirez, Saul,
                
              
            
          
        
          
          
          
            
              
                
                  Li, Danny Xie,
                
              
            
          
        
          
          
          
            
              
                
                  Nobis, Gabriel,
                
              
            
          
        
          
          
          
            
              
                
                  Alvarado, Erick Alejandro Munoz,
                
              
            
          
        
          
          
          
            
              
                
                  Jaramillo-Gutierrez, Giovanna,
                
              
            
          
        
          
          
          
            
              
                
                  Matek, Christian,
                
              
            
          
        
          
          
          
            
              
                
                  Shroff, Arun,
                
              
            
          
        
          
          
          
            
              
                
                  Kherif, Ferath,
                
              
            
          
        
          
          
          
            
              
                
                  Sanguinetti, Bruno,
                
              
            
          
        
          
          
          
            
              
                
                  and Wiegand, Thomas
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Machine Learning for Health NeurIPS Workshop</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://proceedings.mlr.press/v136/oala20a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="http://proceedings.mlr.press/v136/oala20a/oala20a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="http://proceedings.mlr.press/v136/oala20a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://slideslive.at/38941015/ml4h-auditing-from-paper-to-practice" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Healthcare systems are currently adapting to digital technologies, producing large quantities of novel data. Based on these data, machine-learning algorithms have been developed to support practitioners in labor-intensive workflows such as diagnosis, prognosis, triage or treatment of disease. However, their translation into medical practice is often hampered by a lack of careful evaluation in different settings. Efforts have started worldwide to establish guidelines for evaluating machine learning for health (ML4H) tools, highlighting the necessity to evaluate models for bias, interpretability, robustness, and possible failure modes. However, testing and adopting these guidelines in practice remains an open challenge. In this work, we target the paper-to-practice gap by applying an ML4H audit framework proposed by the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) to three use cases: diagnostic prediction of diabetic retinopathy, diagnostic prediction of Alzheimer’s disease, and cytomorphologic classification for leukemia diagnostics. The assessment comprises dimensions such as bias, interpretability, and robustness. Our results highlight the importance of fine-grained and caseadapted quality assessment, provide support for incorporating proposed quality assessment considerations of ML4H during the entire development life cycle, and suggest improvements for future ML4H reference evaluation frameworks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  

  
    <award class="badge">Spotlight<br>Top 10%</award>
  

  </div>

  <div id="OalUDL20" class="col-sm-8">
    
      <div class="title">Detecting Failure Modes in Image Reconstructions with Interval Neural Network Uncertainty</div>
      <div class="author">
        
          
          
          
            
              
                
                  Oala, Luis,
                
              
            
          
        
          
          
          
            
              
                
                  Heiß, Cosmas,
                
              
            
          
        
          
          
          
            
              
                
                  Macdonald, Jan,
                
              
            
          
        
          
          
          
            
              
                
                  März, Maximilian,
                
              
            
          
        
          
          
          
            
              
                
                  Samek, Wojciech,
                
              
            
          
        
          
          
          
            
              
                
                  and Kutyniok, Gitta
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ICML 2020 Workshop on Uncertainty & Robustness in Deep Learning</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://sites.google.com/view/udlworkshop2020/home" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="http://www.gatsby.ucl.ac.uk/ balaji/udl2020/accepted-papers/UDL2020-paper-011.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/aiaudit/assets/pdf/" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://slideslive.com/38930948" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The quantitative detection of failure modes is important for making deep neural networks reliable and usable at scale. We consider three examples for failure modes in image reconstruction problems and demonstrate the potential of uncertainty quantification as a fine-grained alarm system. We propose a deterministic, modular and lightweight approach, called Interval Neural Networks, that produces fast and easy to interpret uncertainty scores which improve the detection of failure modes across four out of five image reconstruction experiments.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    <!-- &copy; Copyright 2021 aiaudit.org  . -->
    Thanks to <a href="https://github.com/alshedivat/al-folio">Maruan</a> for the neat theme base

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/aiaudit/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/aiaudit/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/aiaudit/assets/js/dark_mode.js"></script>


</html>
